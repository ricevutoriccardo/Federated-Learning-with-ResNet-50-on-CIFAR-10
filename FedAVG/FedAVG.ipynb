{"cells":[{"cell_type":"markdown","source":["\n","<H1> FedAVG\n"],"metadata":{"id":"wC_2OktmYKYb"}},{"cell_type":"markdown","metadata":{"id":"TSmy5KK8DhTD"},"source":["Connect the Notebook with GoogleDrive"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17848,"status":"ok","timestamp":1675870021750,"user":{"displayName":"Alessandro","userId":"00700822641677625485"},"user_tz":-60},"id":"IiRQXbhwDcR5","outputId":"9a5cbcb9-de5f-4aa5-9985-a4cd20441bee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import sys\n","sys.path.insert(0, '/content/drive/MyDrive/FL2022/FedAVG')"]},{"cell_type":"markdown","metadata":{"id":"WqI1MfzJEUiE"},"source":["Import Libraries"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Nm5WvZ7JDv-h","executionInfo":{"status":"ok","timestamp":1675870029878,"user_tz":-60,"elapsed":8131,"user":{"displayName":"Alessandro","userId":"00700822641677625485"}}},"outputs":[],"source":["from options import args_parser\n","from update import LocalUpdate, test_inference, client_update, server_aggregate, test\n","from utils import get_dataset, average_weights, weighted_average_weights, exp_details, plot_client_distribution, get_n_params\n","from modelRN50 import ResNet50\n","import torch\n","torch.cuda.empty_cache()\n","import torch.optim as optim\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm # progress bar\n","import copy\n","from torch.utils.tensorboard import SummaryWriter\n","logger = SummaryWriter('../logs')"]},{"cell_type":"markdown","metadata":{"id":"cAs5kKfYFhDf"},"source":["Set the parameters for the training "]},{"cell_type":"code","execution_count":3,"metadata":{"id":"xBLk72aQFAP_","executionInfo":{"status":"ok","timestamp":1675870029879,"user_tz":-60,"elapsed":7,"user":{"displayName":"Alessandro","userId":"00700822641677625485"}}},"outputs":[],"source":["sys.argv=['',\n","          '--iid=1',  #0 -> NONiid, 1 -> iid\n","          '--num_users=100',\n","          '--lr=0.0001',\n","          '--local_ep=1',\n","          '--epochs=300',\n","          '--optimizer=adam',\n","          '--norm=batch_norm',\n","          '--local_bs=10',\n","          '--dataset=cifar',\n","          '--loss=CrossEntropyLoss',\n","          '--gpu=/device:GPU:0']\n","args=args_parser()\n","num_selected = int( args.num_users * args.frac )\n","baseline_num = 100 # number of baseline images to be saved on the global server\n","                   # for retraining of the client's model before aggregation\n","unbalanced = False # if True the clients will contain different number of classes\n","verbose = False"]},{"cell_type":"markdown","metadata":{"id":"nQ0gPP7cFROS"},"source":["Set the device on cuda"]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","if verbose:\n"," print(f\"Device available: {device}\")"],"metadata":{"id":"aMig_MUPKu7a","executionInfo":{"status":"ok","timestamp":1675870030926,"user_tz":-60,"elapsed":1053,"user":{"displayName":"Alessandro","userId":"00700822641677625485"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A1uLnqnsGGd2"},"source":["###Build the Model ResNet-50"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Xg1tFjXJGGJc","executionInfo":{"status":"ok","timestamp":1675870036689,"user_tz":-60,"elapsed":5769,"user":{"displayName":"Alessandro","userId":"00700822641677625485"}}},"outputs":[],"source":["global_model = ResNet50(args.norm)\n","global_model.to(device)\n","global_model.train()\n","if verbose:\n","  print(global_model)\n","  print(f\"Number of Parameters: {get_n_params(global_model)}\")\n","\n","global_weights = global_model.state_dict()\n","client_models = [ global_model for _ in range(num_selected)]\n","\n","# Synchronizing the clients with the global model \n","for model in client_models:\n","    model.load_state_dict(global_model.state_dict()) \n","# Optimizer selection\n","if args.optimizer == 'sgd':\n","    opt = [optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.wd) for model in client_models]\n","elif args.optimizer == 'adam':\n","    opt = [optim.Adam(model.parameters(), lr=args.lr,  weight_decay=args.wd) for model in client_models]"]},{"cell_type":"markdown","source":["####Dataset split:"],"metadata":{"id":"Fkjqo3RYLvb_"}},{"cell_type":"code","source":["train_dataset, test_dataset, user_groups = get_dataset(args=args, unbalanced=unbalanced,)\n","if verbose:\n","  plot_client_distribution(user_groups, train_dataset)\n"],"metadata":{"id":"UuuyqdgXcLM2","colab":{"base_uri":"https://localhost:8080/","height":149,"referenced_widgets":["69935a36e45e41738f057902a303ba96","a874d9c8045244bcb0fb4c41facb105e","4550731bfd294f33be2ea4b14f4a03a1","c7abc91bf8f44bb4b7b05bcc1806aff6","5092fda393a74d0b906117ac12d11f8f","26b2b519bbb7483cba08c35ab05fcd0a","5b63a9fee58c43b88a5ae6afd7dedd87","942a1558abce4d7190c0df65b1cbf508","71b8d149b1bc4caf8e687e3607e70678","8ae0f63a6d594aaeab195360d7b193be","c59d153341c2437cbc451b2fc34aa37d"]},"executionInfo":{"status":"ok","timestamp":1675870045412,"user_tz":-60,"elapsed":8728,"user":{"displayName":"Alessandro","userId":"00700822641677625485"}},"outputId":"b504c1c6-7602-4d9d-e374-eb2e39ab22a1"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/170498071 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69935a36e45e41738f057902a303ba96"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting data/cifar-10-python.tar.gz to data\n","Files already downloaded and verified\n"]}]},{"cell_type":"markdown","metadata":{"id":"xrNWvkQ_HPhy"},"source":["#Training"]},{"cell_type":"code","source":["# training\n","train_loss, train_accuracy = [], []\n","test_acc_list, test_loss_list = [], []\n","\n","for epoch in range(1, args.epochs+1):\n","    local_weights = []\n","    local_losses = []\n","    print(f'Epoch: {epoch} \\n')\n","    model.train()\n","    m = max(int(args.frac * args.num_users), 1) # num of users, at least 1\n","    idxs_users = np.random.choice(range(args.num_users), m, replace=False) \n","\n","    for idx in idxs_users: \n","        local_model = LocalUpdate(args=args, dataset=train_dataset, idxs=user_groups[idx],logger=logger)\n","        w, loss = local_model.update_weights(model=copy.deepcopy(model), # pass the global model to the clients\n","                                             global_round=epoch)\n","        print('| Client : {} | Average Loss: {:.4f} '.format(idx, loss))\n","        local_weights.append(copy.deepcopy(w))\n","        local_losses.append(copy.deepcopy(loss))\n","\n","    # compute global weights (average of local weights)\n","    if unbalanced:\n","        global_weights = weighted_average_weights(local_weights, user_groups, idxs_users)\n","    else:\n","        global_weights = average_weights(local_weights)\n","\n","    # update weights of the global model\n","    model.load_state_dict(global_weights)\n","\n","    # compute average loss\n","    loss_avg = sum(local_losses) / len(local_losses)\n","    train_loss.append(loss_avg)\n","\n","    model.eval()\n","\n","    # calculate avg training accuracy over all users at every epoch\n","    list_acc, list_loss = [], []\n","    for client in range(args.num_users): \n","        local_model = LocalUpdate(args=args, dataset=train_dataset, idxs=user_groups[client],logger=logger)\n","        acc, loss = local_model.inference(model=model)\n","        list_acc.append(acc)\n","        list_loss.append(loss)\n","\n","    train_accuracy.append(sum(list_acc)/len(list_acc))\n","    print(f'\\nAverage training statistics (global epoch) : {epoch}')\n","    print(f'|---- Trainig Loss : {np.mean(np.array(train_loss))}')\n","    print('|---- Training Accuracy: {:.2f}% \\n'.format(100*train_accuracy[-1]))\n","    test_loss, test_acc = test(args, model,global_model, test_dataset)\n","    test_acc_list.append(test_acc)\n","    test_loss_list.append(test_loss)\n","    print('%d-th round' %epoch)\n","    print('average train loss %0.3g | test loss %0.3g | test acc: %0.3f' % (loss / num_selected, test_loss, acc))"],"metadata":{"id":"FmzugEnsXzz1","executionInfo":{"status":"error","timestamp":1675870782301,"user_tz":-60,"elapsed":736892,"user":{"displayName":"Alessandro","userId":"00700822641677625485"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"fdeff7c1-b99e-4a9a-967c-08cadf099610"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 1 \n","\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/MyDrive/FL2022/FedAVG/update.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  return torch.tensor(image), torch.tensor(label)\n"]},{"output_type":"stream","name":"stdout","text":["| Global Round : 1 | Local Epoch : 1 | Loss: 2.466485 | Accuracy: 9.78%\n","| Global Round : 1 |\tLoss avg: 2.466485 \n","| Client : 55 | Average Loss: 2.4665 \n","| Global Round : 1 | Local Epoch : 1 | Loss: 2.489828 | Accuracy: 10.22%\n","| Global Round : 1 |\tLoss avg: 2.489828 \n","| Client : 98 | Average Loss: 2.4898 \n","| Global Round : 1 | Local Epoch : 1 | Loss: 2.414156 | Accuracy: 12.89%\n","| Global Round : 1 |\tLoss avg: 2.414156 \n","| Client : 39 | Average Loss: 2.4142 \n","| Global Round : 1 | Local Epoch : 1 | Loss: 2.393677 | Accuracy: 11.78%\n","| Global Round : 1 |\tLoss avg: 2.393677 \n","| Client : 95 | Average Loss: 2.3937 \n","| Global Round : 1 | Local Epoch : 1 | Loss: 2.378166 | Accuracy: 11.56%\n","| Global Round : 1 |\tLoss avg: 2.378166 \n","| Client : 23 | Average Loss: 2.3782 \n","| Global Round : 1 | Local Epoch : 1 | Loss: 2.383941 | Accuracy: 13.11%\n","| Global Round : 1 |\tLoss avg: 2.383941 \n","| Client : 36 | Average Loss: 2.3839 \n","| Global Round : 1 | Local Epoch : 1 | Loss: 2.431785 | Accuracy: 12.67%\n","| Global Round : 1 |\tLoss avg: 2.431785 \n","| Client : 93 | Average Loss: 2.4318 \n","| Global Round : 1 | Local Epoch : 1 | Loss: 2.406127 | Accuracy: 13.33%\n","| Global Round : 1 |\tLoss avg: 2.406127 \n","| Client : 26 | Average Loss: 2.4061 \n","| Global Round : 1 | Local Epoch : 1 | Loss: 2.426059 | Accuracy: 10.44%\n","| Global Round : 1 |\tLoss avg: 2.426059 \n","| Client : 1 | Average Loss: 2.4261 \n","| Global Round : 1 | Local Epoch : 1 | Loss: 2.413467 | Accuracy: 12.00%\n","| Global Round : 1 |\tLoss avg: 2.413467 \n","| Client : 71 | Average Loss: 2.4135 \n","\n","Average training statistics (global epoch) : 1\n","|---- Trainig Loss : 2.4203691381878323\n","|---- Training Accuracy: 11.32% \n","\n","1-th round\n","average train loss 0.242 | test loss 0.246 | test acc: 0.040\n","Epoch: 2 \n","\n","| Global Round : 2 | Local Epoch : 1 | Loss: 2.248215 | Accuracy: 18.44%\n","| Global Round : 2 |\tLoss avg: 2.248215 \n","| Client : 57 | Average Loss: 2.2482 \n","| Global Round : 2 | Local Epoch : 1 | Loss: 2.313558 | Accuracy: 13.11%\n","| Global Round : 2 |\tLoss avg: 2.313558 \n","| Client : 60 | Average Loss: 2.3136 \n","| Global Round : 2 | Local Epoch : 1 | Loss: 2.256001 | Accuracy: 16.00%\n","| Global Round : 2 |\tLoss avg: 2.256001 \n","| Client : 22 | Average Loss: 2.2560 \n","| Global Round : 2 | Local Epoch : 1 | Loss: 2.295022 | Accuracy: 15.11%\n","| Global Round : 2 |\tLoss avg: 2.295022 \n","| Client : 94 | Average Loss: 2.2950 \n","| Global Round : 2 | Local Epoch : 1 | Loss: 2.321310 | Accuracy: 13.78%\n","| Global Round : 2 |\tLoss avg: 2.321310 \n","| Client : 13 | Average Loss: 2.3213 \n","| Global Round : 2 | Local Epoch : 1 | Loss: 2.289181 | Accuracy: 13.56%\n","| Global Round : 2 |\tLoss avg: 2.289181 \n","| Client : 70 | Average Loss: 2.2892 \n","| Global Round : 2 | Local Epoch : 1 | Loss: 2.325756 | Accuracy: 18.00%\n","| Global Round : 2 |\tLoss avg: 2.325756 \n","| Client : 33 | Average Loss: 2.3258 \n","| Global Round : 2 | Local Epoch : 1 | Loss: 2.303555 | Accuracy: 16.22%\n","| Global Round : 2 |\tLoss avg: 2.303555 \n","| Client : 46 | Average Loss: 2.3036 \n","| Global Round : 2 | Local Epoch : 1 | Loss: 2.293480 | Accuracy: 14.00%\n","| Global Round : 2 |\tLoss avg: 2.293480 \n","| Client : 38 | Average Loss: 2.2935 \n","| Global Round : 2 | Local Epoch : 1 | Loss: 2.362819 | Accuracy: 12.89%\n","| Global Round : 2 |\tLoss avg: 2.362819 \n","| Client : 39 | Average Loss: 2.3628 \n","\n","Average training statistics (global epoch) : 2\n","|---- Trainig Loss : 2.3606294816070132\n","|---- Training Accuracy: 18.68% \n","\n","2-th round\n","average train loss 0.225 | test loss 0.223 | test acc: 0.080\n","Epoch: 3 \n","\n","| Global Round : 3 | Local Epoch : 1 | Loss: 2.243845 | Accuracy: 21.11%\n","| Global Round : 3 |\tLoss avg: 2.243845 \n","| Client : 80 | Average Loss: 2.2438 \n","| Global Round : 3 | Local Epoch : 1 | Loss: 2.189050 | Accuracy: 19.33%\n","| Global Round : 3 |\tLoss avg: 2.189050 \n","| Client : 24 | Average Loss: 2.1891 \n","| Global Round : 3 | Local Epoch : 1 | Loss: 2.230783 | Accuracy: 18.67%\n","| Global Round : 3 |\tLoss avg: 2.230783 \n","| Client : 87 | Average Loss: 2.2308 \n","| Global Round : 3 | Local Epoch : 1 | Loss: 2.269065 | Accuracy: 16.67%\n","| Global Round : 3 |\tLoss avg: 2.269065 \n","| Client : 92 | Average Loss: 2.2691 \n","| Global Round : 3 | Local Epoch : 1 | Loss: 2.207047 | Accuracy: 17.78%\n","| Global Round : 3 |\tLoss avg: 2.207047 \n","| Client : 20 | Average Loss: 2.2070 \n","| Global Round : 3 | Local Epoch : 1 | Loss: 2.136220 | Accuracy: 22.00%\n","| Global Round : 3 |\tLoss avg: 2.136220 \n","| Client : 97 | Average Loss: 2.1362 \n","| Global Round : 3 | Local Epoch : 1 | Loss: 2.220327 | Accuracy: 17.56%\n","| Global Round : 3 |\tLoss avg: 2.220327 \n","| Client : 18 | Average Loss: 2.2203 \n","| Global Round : 3 | Local Epoch : 1 | Loss: 2.267525 | Accuracy: 14.67%\n","| Global Round : 3 |\tLoss avg: 2.267525 \n","| Client : 21 | Average Loss: 2.2675 \n","| Global Round : 3 | Local Epoch : 1 | Loss: 2.235304 | Accuracy: 16.89%\n","| Global Round : 3 |\tLoss avg: 2.235304 \n","| Client : 68 | Average Loss: 2.2353 \n","| Global Round : 3 | Local Epoch : 1 | Loss: 2.256709 | Accuracy: 14.89%\n","| Global Round : 3 |\tLoss avg: 2.256709 \n","| Client : 50 | Average Loss: 2.2567 \n","\n","Average training statistics (global epoch) : 3\n","|---- Trainig Loss : 2.315615459371496\n","|---- Training Accuracy: 17.38% \n","\n","3-th round\n","average train loss 0.289 | test loss 0.22 | test acc: 0.100\n","Epoch: 4 \n","\n","| Global Round : 4 | Local Epoch : 1 | Loss: 2.162820 | Accuracy: 16.22%\n","| Global Round : 4 |\tLoss avg: 2.162820 \n","| Client : 32 | Average Loss: 2.1628 \n","| Global Round : 4 | Local Epoch : 1 | Loss: 2.156534 | Accuracy: 19.33%\n","| Global Round : 4 |\tLoss avg: 2.156534 \n","| Client : 10 | Average Loss: 2.1565 \n","| Global Round : 4 | Local Epoch : 1 | Loss: 2.202876 | Accuracy: 18.67%\n","| Global Round : 4 |\tLoss avg: 2.202876 \n","| Client : 13 | Average Loss: 2.2029 \n","| Global Round : 4 | Local Epoch : 1 | Loss: 2.212784 | Accuracy: 17.78%\n","| Global Round : 4 |\tLoss avg: 2.212784 \n","| Client : 83 | Average Loss: 2.2128 \n","| Global Round : 4 | Local Epoch : 1 | Loss: 2.186999 | Accuracy: 16.22%\n","| Global Round : 4 |\tLoss avg: 2.186999 \n","| Client : 31 | Average Loss: 2.1870 \n","| Global Round : 4 | Local Epoch : 1 | Loss: 2.187751 | Accuracy: 17.11%\n","| Global Round : 4 |\tLoss avg: 2.187751 \n","| Client : 57 | Average Loss: 2.1878 \n","| Global Round : 4 | Local Epoch : 1 | Loss: 2.183506 | Accuracy: 20.44%\n","| Global Round : 4 |\tLoss avg: 2.183506 \n","| Client : 33 | Average Loss: 2.1835 \n","| Global Round : 4 | Local Epoch : 1 | Loss: 2.172731 | Accuracy: 19.33%\n","| Global Round : 4 |\tLoss avg: 2.172731 \n","| Client : 44 | Average Loss: 2.1727 \n","| Global Round : 4 | Local Epoch : 1 | Loss: 2.123487 | Accuracy: 22.44%\n","| Global Round : 4 |\tLoss avg: 2.123487 \n","| Client : 94 | Average Loss: 2.1235 \n","| Global Round : 4 | Local Epoch : 1 | Loss: 2.195779 | Accuracy: 18.89%\n","| Global Round : 4 |\tLoss avg: 2.195779 \n","| Client : 90 | Average Loss: 2.1958 \n","\n","Average training statistics (global epoch) : 4\n","|---- Trainig Loss : 2.281343289679951\n","|---- Training Accuracy: 20.32% \n","\n","4-th round\n","average train loss 0.268 | test loss 0.22 | test acc: 0.080\n","Epoch: 5 \n","\n","| Global Round : 5 | Local Epoch : 1 | Loss: 2.094061 | Accuracy: 20.44%\n","| Global Round : 5 |\tLoss avg: 2.094061 \n","| Client : 12 | Average Loss: 2.0941 \n","| Global Round : 5 | Local Epoch : 1 | Loss: 2.144219 | Accuracy: 22.89%\n","| Global Round : 5 |\tLoss avg: 2.144219 \n","| Client : 11 | Average Loss: 2.1442 \n","| Global Round : 5 | Local Epoch : 1 | Loss: 2.038367 | Accuracy: 20.67%\n","| Global Round : 5 |\tLoss avg: 2.038367 \n","| Client : 96 | Average Loss: 2.0384 \n","| Global Round : 5 | Local Epoch : 1 | Loss: 2.187608 | Accuracy: 18.00%\n","| Global Round : 5 |\tLoss avg: 2.187608 \n","| Client : 28 | Average Loss: 2.1876 \n","| Global Round : 5 | Local Epoch : 1 | Loss: 2.126723 | Accuracy: 24.00%\n","| Global Round : 5 |\tLoss avg: 2.126723 \n","| Client : 48 | Average Loss: 2.1267 \n","| Global Round : 5 | Local Epoch : 1 | Loss: 2.081079 | Accuracy: 24.89%\n","| Global Round : 5 |\tLoss avg: 2.081079 \n","| Client : 45 | Average Loss: 2.0811 \n","| Global Round : 5 | Local Epoch : 1 | Loss: 2.144779 | Accuracy: 20.22%\n","| Global Round : 5 |\tLoss avg: 2.144779 \n","| Client : 80 | Average Loss: 2.1448 \n","| Global Round : 5 | Local Epoch : 1 | Loss: 2.145607 | Accuracy: 22.89%\n","| Global Round : 5 |\tLoss avg: 2.145607 \n","| Client : 46 | Average Loss: 2.1456 \n","| Global Round : 5 | Local Epoch : 1 | Loss: 2.122637 | Accuracy: 21.33%\n","| Global Round : 5 |\tLoss avg: 2.122637 \n","| Client : 30 | Average Loss: 2.1226 \n","| Global Round : 5 | Local Epoch : 1 | Loss: 2.150408 | Accuracy: 20.00%\n","| Global Round : 5 |\tLoss avg: 2.150408 \n","| Client : 26 | Average Loss: 2.1504 \n","\n","Average training statistics (global epoch) : 5\n","|---- Trainig Loss : 2.2497843556404113\n","|---- Training Accuracy: 22.54% \n","\n","5-th round\n","average train loss 0.234 | test loss 0.216 | test acc: 0.060\n","Epoch: 6 \n","\n","| Global Round : 6 | Local Epoch : 1 | Loss: 2.108578 | Accuracy: 20.00%\n","| Global Round : 6 |\tLoss avg: 2.108578 \n","| Client : 85 | Average Loss: 2.1086 \n","| Global Round : 6 | Local Epoch : 1 | Loss: 2.079615 | Accuracy: 21.33%\n","| Global Round : 6 |\tLoss avg: 2.079615 \n","| Client : 7 | Average Loss: 2.0796 \n","| Global Round : 6 | Local Epoch : 1 | Loss: 2.083036 | Accuracy: 21.56%\n","| Global Round : 6 |\tLoss avg: 2.083036 \n","| Client : 61 | Average Loss: 2.0830 \n","| Global Round : 6 | Local Epoch : 1 | Loss: 2.099760 | Accuracy: 22.00%\n","| Global Round : 6 |\tLoss avg: 2.099760 \n","| Client : 39 | Average Loss: 2.0998 \n","| Global Round : 6 | Local Epoch : 1 | Loss: 2.176690 | Accuracy: 21.56%\n","| Global Round : 6 |\tLoss avg: 2.176690 \n","| Client : 73 | Average Loss: 2.1767 \n","| Global Round : 6 | Local Epoch : 1 | Loss: 2.070255 | Accuracy: 24.89%\n","| Global Round : 6 |\tLoss avg: 2.070255 \n","| Client : 63 | Average Loss: 2.0703 \n","| Global Round : 6 | Local Epoch : 1 | Loss: 2.105704 | Accuracy: 22.67%\n","| Global Round : 6 |\tLoss avg: 2.105704 \n","| Client : 28 | Average Loss: 2.1057 \n","| Global Round : 6 | Local Epoch : 1 | Loss: 2.107133 | Accuracy: 20.67%\n","| Global Round : 6 |\tLoss avg: 2.107133 \n","| Client : 60 | Average Loss: 2.1071 \n","| Global Round : 6 | Local Epoch : 1 | Loss: 2.130455 | Accuracy: 24.89%\n","| Global Round : 6 |\tLoss avg: 2.130455 \n","| Client : 65 | Average Loss: 2.1305 \n","| Global Round : 6 | Local Epoch : 1 | Loss: 2.068417 | Accuracy: 22.44%\n","| Global Round : 6 |\tLoss avg: 2.068417 \n","| Client : 58 | Average Loss: 2.0684 \n","\n","Average training statistics (global epoch) : 6\n","|---- Trainig Loss : 2.225314344565074\n","|---- Training Accuracy: 24.02% \n","\n","6-th round\n","average train loss 0.224 | test loss 0.212 | test acc: 0.080\n","Epoch: 7 \n","\n","| Global Round : 7 | Local Epoch : 1 | Loss: 2.162084 | Accuracy: 19.11%\n","| Global Round : 7 |\tLoss avg: 2.162084 \n","| Client : 46 | Average Loss: 2.1621 \n","| Global Round : 7 | Local Epoch : 1 | Loss: 2.143920 | Accuracy: 19.33%\n","| Global Round : 7 |\tLoss avg: 2.143920 \n","| Client : 5 | Average Loss: 2.1439 \n","| Global Round : 7 | Local Epoch : 1 | Loss: 2.083813 | Accuracy: 22.89%\n","| Global Round : 7 |\tLoss avg: 2.083813 \n","| Client : 93 | Average Loss: 2.0838 \n","| Global Round : 7 | Local Epoch : 1 | Loss: 2.048750 | Accuracy: 22.89%\n","| Global Round : 7 |\tLoss avg: 2.048750 \n","| Client : 50 | Average Loss: 2.0487 \n","| Global Round : 7 | Local Epoch : 1 | Loss: 2.046675 | Accuracy: 24.67%\n","| Global Round : 7 |\tLoss avg: 2.046675 \n","| Client : 45 | Average Loss: 2.0467 \n","| Global Round : 7 | Local Epoch : 1 | Loss: 2.102183 | Accuracy: 20.22%\n","| Global Round : 7 |\tLoss avg: 2.102183 \n","| Client : 87 | Average Loss: 2.1022 \n","| Global Round : 7 | Local Epoch : 1 | Loss: 2.032077 | Accuracy: 25.33%\n","| Global Round : 7 |\tLoss avg: 2.032077 \n","| Client : 88 | Average Loss: 2.0321 \n","| Global Round : 7 | Local Epoch : 1 | Loss: 2.105814 | Accuracy: 20.89%\n","| Global Round : 7 |\tLoss avg: 2.105814 \n","| Client : 54 | Average Loss: 2.1058 \n","| Global Round : 7 | Local Epoch : 1 | Loss: 2.130560 | Accuracy: 20.22%\n","| Global Round : 7 |\tLoss avg: 2.130560 \n","| Client : 25 | Average Loss: 2.1306 \n","| Global Round : 7 | Local Epoch : 1 | Loss: 2.023251 | Accuracy: 23.78%\n","| Global Round : 7 |\tLoss avg: 2.023251 \n","| Client : 96 | Average Loss: 2.0233 \n","\n","Average training statistics (global epoch) : 7\n","|---- Trainig Loss : 2.2056855245998928\n","|---- Training Accuracy: 26.66% \n","\n","7-th round\n","average train loss 0.238 | test loss 0.208 | test acc: 0.200\n","Epoch: 8 \n","\n","| Global Round : 8 | Local Epoch : 1 | Loss: 2.076585 | Accuracy: 22.00%\n","| Global Round : 8 |\tLoss avg: 2.076585 \n","| Client : 52 | Average Loss: 2.0766 \n","| Global Round : 8 | Local Epoch : 1 | Loss: 2.079752 | Accuracy: 21.78%\n","| Global Round : 8 |\tLoss avg: 2.079752 \n","| Client : 31 | Average Loss: 2.0798 \n","| Global Round : 8 | Local Epoch : 1 | Loss: 2.043623 | Accuracy: 24.00%\n","| Global Round : 8 |\tLoss avg: 2.043623 \n","| Client : 18 | Average Loss: 2.0436 \n","| Global Round : 8 | Local Epoch : 1 | Loss: 2.020541 | Accuracy: 27.56%\n","| Global Round : 8 |\tLoss avg: 2.020541 \n","| Client : 73 | Average Loss: 2.0205 \n","| Global Round : 8 | Local Epoch : 1 | Loss: 2.085103 | Accuracy: 22.22%\n","| Global Round : 8 |\tLoss avg: 2.085103 \n","| Client : 27 | Average Loss: 2.0851 \n","| Global Round : 8 | Local Epoch : 1 | Loss: 2.026355 | Accuracy: 27.78%\n","| Global Round : 8 |\tLoss avg: 2.026355 \n","| Client : 14 | Average Loss: 2.0264 \n","| Global Round : 8 | Local Epoch : 1 | Loss: 2.002434 | Accuracy: 25.78%\n","| Global Round : 8 |\tLoss avg: 2.002434 \n","| Client : 19 | Average Loss: 2.0024 \n","| Global Round : 8 | Local Epoch : 1 | Loss: 2.032491 | Accuracy: 24.44%\n","| Global Round : 8 |\tLoss avg: 2.032491 \n","| Client : 25 | Average Loss: 2.0325 \n","| Global Round : 8 | Local Epoch : 1 | Loss: 2.040575 | Accuracy: 23.78%\n","| Global Round : 8 |\tLoss avg: 2.040575 \n","| Client : 59 | Average Loss: 2.0406 \n","| Global Round : 8 | Local Epoch : 1 | Loss: 2.004011 | Accuracy: 27.56%\n","| Global Round : 8 |\tLoss avg: 2.004011 \n","| Client : 42 | Average Loss: 2.0040 \n","\n","Average training statistics (global epoch) : 8\n","|---- Trainig Loss : 2.185118208593792\n","|---- Training Accuracy: 28.16% \n","\n","8-th round\n","average train loss 0.234 | test loss 0.199 | test acc: 0.180\n","Epoch: 9 \n","\n","| Global Round : 9 | Local Epoch : 1 | Loss: 2.044227 | Accuracy: 24.44%\n","| Global Round : 9 |\tLoss avg: 2.044227 \n","| Client : 11 | Average Loss: 2.0442 \n","| Global Round : 9 | Local Epoch : 1 | Loss: 2.004699 | Accuracy: 24.44%\n","| Global Round : 9 |\tLoss avg: 2.004699 \n","| Client : 96 | Average Loss: 2.0047 \n","| Global Round : 9 | Local Epoch : 1 | Loss: 2.053595 | Accuracy: 23.56%\n","| Global Round : 9 |\tLoss avg: 2.053595 \n","| Client : 68 | Average Loss: 2.0536 \n","| Global Round : 9 | Local Epoch : 1 | Loss: 2.073527 | Accuracy: 24.89%\n","| Global Round : 9 |\tLoss avg: 2.073527 \n","| Client : 73 | Average Loss: 2.0735 \n","| Global Round : 9 | Local Epoch : 1 | Loss: 1.996529 | Accuracy: 29.11%\n","| Global Round : 9 |\tLoss avg: 1.996529 \n","| Client : 39 | Average Loss: 1.9965 \n","| Global Round : 9 | Local Epoch : 1 | Loss: 2.041463 | Accuracy: 23.11%\n","| Global Round : 9 |\tLoss avg: 2.041463 \n","| Client : 74 | Average Loss: 2.0415 \n","| Global Round : 9 | Local Epoch : 1 | Loss: 2.091553 | Accuracy: 21.33%\n","| Global Round : 9 |\tLoss avg: 2.091553 \n","| Client : 90 | Average Loss: 2.0916 \n","| Global Round : 9 | Local Epoch : 1 | Loss: 1.966921 | Accuracy: 24.67%\n","| Global Round : 9 |\tLoss avg: 1.966921 \n","| Client : 82 | Average Loss: 1.9669 \n","| Global Round : 9 | Local Epoch : 1 | Loss: 2.019547 | Accuracy: 22.89%\n","| Global Round : 9 |\tLoss avg: 2.019547 \n","| Client : 53 | Average Loss: 2.0195 \n","| Global Round : 9 | Local Epoch : 1 | Loss: 2.004569 | Accuracy: 23.11%\n","| Global Round : 9 |\tLoss avg: 2.004569 \n","| Client : 98 | Average Loss: 2.0046 \n","\n","Average training statistics (global epoch) : 9\n","|---- Trainig Loss : 2.1678454048839613\n","|---- Training Accuracy: 28.24% \n","\n","9-th round\n","average train loss 0.226 | test loss 0.201 | test acc: 0.180\n","Epoch: 10 \n","\n","| Global Round : 10 | Local Epoch : 1 | Loss: 1.995358 | Accuracy: 26.44%\n","| Global Round : 10 |\tLoss avg: 1.995358 \n","| Client : 8 | Average Loss: 1.9954 \n","| Global Round : 10 | Local Epoch : 1 | Loss: 1.998966 | Accuracy: 27.78%\n","| Global Round : 10 |\tLoss avg: 1.998966 \n","| Client : 97 | Average Loss: 1.9990 \n","| Global Round : 10 | Local Epoch : 1 | Loss: 1.964613 | Accuracy: 25.33%\n","| Global Round : 10 |\tLoss avg: 1.964613 \n","| Client : 33 | Average Loss: 1.9646 \n","| Global Round : 10 | Local Epoch : 1 | Loss: 2.077801 | Accuracy: 23.11%\n","| Global Round : 10 |\tLoss avg: 2.077801 \n","| Client : 13 | Average Loss: 2.0778 \n","| Global Round : 10 | Local Epoch : 1 | Loss: 1.988925 | Accuracy: 27.33%\n","| Global Round : 10 |\tLoss avg: 1.988925 \n","| Client : 41 | Average Loss: 1.9889 \n","| Global Round : 10 | Local Epoch : 1 | Loss: 1.978138 | Accuracy: 25.78%\n","| Global Round : 10 |\tLoss avg: 1.978138 \n","| Client : 61 | Average Loss: 1.9781 \n","| Global Round : 10 | Local Epoch : 1 | Loss: 2.121650 | Accuracy: 22.00%\n","| Global Round : 10 |\tLoss avg: 2.121650 \n","| Client : 14 | Average Loss: 2.1217 \n","| Global Round : 10 | Local Epoch : 1 | Loss: 1.941840 | Accuracy: 28.00%\n","| Global Round : 10 |\tLoss avg: 1.941840 \n","| Client : 66 | Average Loss: 1.9418 \n","| Global Round : 10 | Local Epoch : 1 | Loss: 2.020077 | Accuracy: 26.44%\n","| Global Round : 10 |\tLoss avg: 2.020077 \n","| Client : 73 | Average Loss: 2.0201 \n","| Global Round : 10 | Local Epoch : 1 | Loss: 1.982731 | Accuracy: 26.00%\n","| Global Round : 10 |\tLoss avg: 1.982731 \n","| Client : 9 | Average Loss: 1.9827 \n","\n","Average training statistics (global epoch) : 10\n","|---- Trainig Loss : 2.1517618539333343\n","|---- Training Accuracy: 28.76% \n","\n","10-th round\n","average train loss 0.246 | test loss 0.197 | test acc: 0.260\n","Epoch: 11 \n","\n","| Global Round : 11 | Local Epoch : 1 | Loss: 2.009980 | Accuracy: 27.33%\n","| Global Round : 11 |\tLoss avg: 2.009980 \n","| Client : 37 | Average Loss: 2.0100 \n","| Global Round : 11 | Local Epoch : 1 | Loss: 1.960133 | Accuracy: 26.00%\n","| Global Round : 11 |\tLoss avg: 1.960133 \n","| Client : 61 | Average Loss: 1.9601 \n","| Global Round : 11 | Local Epoch : 1 | Loss: 1.907210 | Accuracy: 30.00%\n","| Global Round : 11 |\tLoss avg: 1.907210 \n","| Client : 2 | Average Loss: 1.9072 \n","| Global Round : 11 | Local Epoch : 1 | Loss: 2.010221 | Accuracy: 27.11%\n","| Global Round : 11 |\tLoss avg: 2.010221 \n","| Client : 10 | Average Loss: 2.0102 \n","| Global Round : 11 | Local Epoch : 1 | Loss: 2.046643 | Accuracy: 23.33%\n","| Global Round : 11 |\tLoss avg: 2.046643 \n","| Client : 54 | Average Loss: 2.0466 \n","| Global Round : 11 | Local Epoch : 1 | Loss: 1.989474 | Accuracy: 25.11%\n","| Global Round : 11 |\tLoss avg: 1.989474 \n","| Client : 89 | Average Loss: 1.9895 \n","| Global Round : 11 | Local Epoch : 1 | Loss: 1.954885 | Accuracy: 26.44%\n","| Global Round : 11 |\tLoss avg: 1.954885 \n","| Client : 86 | Average Loss: 1.9549 \n","| Global Round : 11 | Local Epoch : 1 | Loss: 1.941206 | Accuracy: 28.22%\n","| Global Round : 11 |\tLoss avg: 1.941206 \n","| Client : 42 | Average Loss: 1.9412 \n","| Global Round : 11 | Local Epoch : 1 | Loss: 2.012361 | Accuracy: 23.56%\n","| Global Round : 11 |\tLoss avg: 2.012361 \n","| Client : 98 | Average Loss: 2.0124 \n","| Global Round : 11 | Local Epoch : 1 | Loss: 2.015388 | Accuracy: 22.89%\n","| Global Round : 11 |\tLoss avg: 2.015388 \n","| Client : 7 | Average Loss: 2.0154 \n","\n","Average training statistics (global epoch) : 11\n","|---- Trainig Loss : 2.136578954590691\n","|---- Training Accuracy: 30.68% \n","\n","11-th round\n","average train loss 0.225 | test loss 0.193 | test acc: 0.220\n","Epoch: 12 \n","\n","| Global Round : 12 | Local Epoch : 1 | Loss: 1.913910 | Accuracy: 26.44%\n","| Global Round : 12 |\tLoss avg: 1.913910 \n","| Client : 38 | Average Loss: 1.9139 \n","| Global Round : 12 | Local Epoch : 1 | Loss: 1.883335 | Accuracy: 32.00%\n","| Global Round : 12 |\tLoss avg: 1.883335 \n","| Client : 9 | Average Loss: 1.8833 \n","| Global Round : 12 | Local Epoch : 1 | Loss: 2.018641 | Accuracy: 23.56%\n","| Global Round : 12 |\tLoss avg: 2.018641 \n","| Client : 24 | Average Loss: 2.0186 \n","| Global Round : 12 | Local Epoch : 1 | Loss: 1.992702 | Accuracy: 29.56%\n","| Global Round : 12 |\tLoss avg: 1.992702 \n","| Client : 20 | Average Loss: 1.9927 \n","| Global Round : 12 | Local Epoch : 1 | Loss: 1.960475 | Accuracy: 24.44%\n","| Global Round : 12 |\tLoss avg: 1.960475 \n","| Client : 27 | Average Loss: 1.9605 \n","| Global Round : 12 | Local Epoch : 1 | Loss: 1.987923 | Accuracy: 27.56%\n","| Global Round : 12 |\tLoss avg: 1.987923 \n","| Client : 49 | Average Loss: 1.9879 \n","| Global Round : 12 | Local Epoch : 1 | Loss: 1.973870 | Accuracy: 28.00%\n","| Global Round : 12 |\tLoss avg: 1.973870 \n","| Client : 67 | Average Loss: 1.9739 \n","| Global Round : 12 | Local Epoch : 1 | Loss: 2.067122 | Accuracy: 22.67%\n","| Global Round : 12 |\tLoss avg: 2.067122 \n","| Client : 70 | Average Loss: 2.0671 \n","| Global Round : 12 | Local Epoch : 1 | Loss: 2.021385 | Accuracy: 24.67%\n","| Global Round : 12 |\tLoss avg: 2.021385 \n","| Client : 31 | Average Loss: 2.0214 \n","| Global Round : 12 | Local Epoch : 1 | Loss: 1.893901 | Accuracy: 29.78%\n","| Global Round : 12 |\tLoss avg: 1.893901 \n","| Client : 36 | Average Loss: 1.8939 \n","\n","Average training statistics (global epoch) : 12\n","|---- Trainig Loss : 2.122807908367227\n","|---- Training Accuracy: 34.12% \n","\n","12-th round\n","average train loss 0.218 | test loss 0.177 | test acc: 0.280\n","Epoch: 13 \n","\n","| Global Round : 13 | Local Epoch : 1 | Loss: 2.036770 | Accuracy: 28.00%\n","| Global Round : 13 |\tLoss avg: 2.036770 \n","| Client : 27 | Average Loss: 2.0368 \n","| Global Round : 13 | Local Epoch : 1 | Loss: 1.883377 | Accuracy: 29.33%\n","| Global Round : 13 |\tLoss avg: 1.883377 \n","| Client : 78 | Average Loss: 1.8834 \n","| Global Round : 13 | Local Epoch : 1 | Loss: 1.876175 | Accuracy: 28.67%\n","| Global Round : 13 |\tLoss avg: 1.876175 \n","| Client : 32 | Average Loss: 1.8762 \n","| Global Round : 13 | Local Epoch : 1 | Loss: 1.944799 | Accuracy: 26.44%\n","| Global Round : 13 |\tLoss avg: 1.944799 \n","| Client : 61 | Average Loss: 1.9448 \n","| Global Round : 13 | Local Epoch : 1 | Loss: 1.972946 | Accuracy: 26.22%\n","| Global Round : 13 |\tLoss avg: 1.972946 \n","| Client : 58 | Average Loss: 1.9729 \n","| Global Round : 13 | Local Epoch : 1 | Loss: 1.943922 | Accuracy: 26.67%\n","| Global Round : 13 |\tLoss avg: 1.943922 \n","| Client : 2 | Average Loss: 1.9439 \n","| Global Round : 13 | Local Epoch : 1 | Loss: 1.927595 | Accuracy: 26.22%\n","| Global Round : 13 |\tLoss avg: 1.927595 \n","| Client : 35 | Average Loss: 1.9276 \n","| Global Round : 13 | Local Epoch : 1 | Loss: 2.000480 | Accuracy: 25.78%\n","| Global Round : 13 |\tLoss avg: 2.000480 \n","| Client : 55 | Average Loss: 2.0005 \n","| Global Round : 13 | Local Epoch : 1 | Loss: 1.942287 | Accuracy: 27.78%\n","| Global Round : 13 |\tLoss avg: 1.942287 \n","| Client : 29 | Average Loss: 1.9423 \n","| Global Round : 13 | Local Epoch : 1 | Loss: 2.014138 | Accuracy: 23.56%\n","| Global Round : 13 |\tLoss avg: 2.014138 \n","| Client : 0 | Average Loss: 2.0141 \n","\n","Average training statistics (global epoch) : 13\n","|---- Trainig Loss : 2.109841825309981\n","|---- Training Accuracy: 31.88% \n","\n","13-th round\n","average train loss 0.219 | test loss 0.187 | test acc: 0.140\n","Epoch: 14 \n","\n","| Global Round : 14 | Local Epoch : 1 | Loss: 1.971069 | Accuracy: 29.33%\n","| Global Round : 14 |\tLoss avg: 1.971069 \n","| Client : 96 | Average Loss: 1.9711 \n","| Global Round : 14 | Local Epoch : 1 | Loss: 1.987854 | Accuracy: 30.44%\n","| Global Round : 14 |\tLoss avg: 1.987854 \n","| Client : 54 | Average Loss: 1.9879 \n","| Global Round : 14 | Local Epoch : 1 | Loss: 1.943696 | Accuracy: 27.11%\n","| Global Round : 14 |\tLoss avg: 1.943696 \n","| Client : 71 | Average Loss: 1.9437 \n","| Global Round : 14 | Local Epoch : 1 | Loss: 1.933450 | Accuracy: 29.78%\n","| Global Round : 14 |\tLoss avg: 1.933450 \n","| Client : 13 | Average Loss: 1.9334 \n","| Global Round : 14 | Local Epoch : 1 | Loss: 1.962278 | Accuracy: 29.78%\n","| Global Round : 14 |\tLoss avg: 1.962278 \n","| Client : 67 | Average Loss: 1.9623 \n","| Global Round : 14 | Local Epoch : 1 | Loss: 1.925201 | Accuracy: 31.33%\n","| Global Round : 14 |\tLoss avg: 1.925201 \n","| Client : 39 | Average Loss: 1.9252 \n","| Global Round : 14 | Local Epoch : 1 | Loss: 2.004818 | Accuracy: 24.00%\n","| Global Round : 14 |\tLoss avg: 2.004818 \n","| Client : 76 | Average Loss: 2.0048 \n","| Global Round : 14 | Local Epoch : 1 | Loss: 1.896636 | Accuracy: 29.11%\n","| Global Round : 14 |\tLoss avg: 1.896636 \n","| Client : 58 | Average Loss: 1.8966 \n","| Global Round : 14 | Local Epoch : 1 | Loss: 1.991990 | Accuracy: 26.44%\n","| Global Round : 14 |\tLoss avg: 1.991990 \n","| Client : 59 | Average Loss: 1.9920 \n","| Global Round : 14 | Local Epoch : 1 | Loss: 1.977446 | Accuracy: 27.78%\n","| Global Round : 14 |\tLoss avg: 1.977446 \n","| Client : 37 | Average Loss: 1.9774 \n","\n","Average training statistics (global epoch) : 14\n","|---- Trainig Loss : 2.0990991119354487\n","|---- Training Accuracy: 33.28% \n","\n","14-th round\n","average train loss 0.204 | test loss 0.18 | test acc: 0.280\n","Epoch: 15 \n","\n","| Global Round : 15 | Local Epoch : 1 | Loss: 1.976499 | Accuracy: 29.33%\n","| Global Round : 15 |\tLoss avg: 1.976499 \n","| Client : 98 | Average Loss: 1.9765 \n","| Global Round : 15 | Local Epoch : 1 | Loss: 1.980243 | Accuracy: 25.78%\n","| Global Round : 15 |\tLoss avg: 1.980243 \n","| Client : 80 | Average Loss: 1.9802 \n","| Global Round : 15 | Local Epoch : 1 | Loss: 1.905055 | Accuracy: 30.00%\n","| Global Round : 15 |\tLoss avg: 1.905055 \n","| Client : 12 | Average Loss: 1.9051 \n","| Global Round : 15 | Local Epoch : 1 | Loss: 1.928740 | Accuracy: 29.78%\n","| Global Round : 15 |\tLoss avg: 1.928740 \n","| Client : 69 | Average Loss: 1.9287 \n","| Global Round : 15 | Local Epoch : 1 | Loss: 1.981376 | Accuracy: 23.33%\n","| Global Round : 15 |\tLoss avg: 1.981376 \n","| Client : 47 | Average Loss: 1.9814 \n","| Global Round : 15 | Local Epoch : 1 | Loss: 1.951510 | Accuracy: 24.44%\n","| Global Round : 15 |\tLoss avg: 1.951510 \n","| Client : 65 | Average Loss: 1.9515 \n","| Global Round : 15 | Local Epoch : 1 | Loss: 1.900615 | Accuracy: 32.67%\n","| Global Round : 15 |\tLoss avg: 1.900615 \n","| Client : 7 | Average Loss: 1.9006 \n","| Global Round : 15 | Local Epoch : 1 | Loss: 1.953671 | Accuracy: 27.33%\n","| Global Round : 15 |\tLoss avg: 1.953671 \n","| Client : 8 | Average Loss: 1.9537 \n","| Global Round : 15 | Local Epoch : 1 | Loss: 1.987479 | Accuracy: 29.11%\n","| Global Round : 15 |\tLoss avg: 1.987479 \n","| Client : 24 | Average Loss: 1.9875 \n","| Global Round : 15 | Local Epoch : 1 | Loss: 1.912462 | Accuracy: 29.56%\n","| Global Round : 15 |\tLoss avg: 1.912462 \n","| Client : 31 | Average Loss: 1.9125 \n","\n","Average training statistics (global epoch) : 15\n","|---- Trainig Loss : 2.089010159563135\n","|---- Training Accuracy: 33.12% \n","\n","15-th round\n","average train loss 0.221 | test loss 0.184 | test acc: 0.320\n","Epoch: 16 \n","\n","| Global Round : 16 | Local Epoch : 1 | Loss: 1.960748 | Accuracy: 25.33%\n","| Global Round : 16 |\tLoss avg: 1.960748 \n","| Client : 59 | Average Loss: 1.9607 \n","| Global Round : 16 | Local Epoch : 1 | Loss: 1.847357 | Accuracy: 28.00%\n","| Global Round : 16 |\tLoss avg: 1.847357 \n","| Client : 22 | Average Loss: 1.8474 \n","| Global Round : 16 | Local Epoch : 1 | Loss: 1.868836 | Accuracy: 31.56%\n","| Global Round : 16 |\tLoss avg: 1.868836 \n","| Client : 94 | Average Loss: 1.8688 \n","| Global Round : 16 | Local Epoch : 1 | Loss: 1.837878 | Accuracy: 35.56%\n","| Global Round : 16 |\tLoss avg: 1.837878 \n","| Client : 45 | Average Loss: 1.8379 \n","| Global Round : 16 | Local Epoch : 1 | Loss: 1.876906 | Accuracy: 33.11%\n","| Global Round : 16 |\tLoss avg: 1.876906 \n","| Client : 51 | Average Loss: 1.8769 \n","| Global Round : 16 | Local Epoch : 1 | Loss: 1.951459 | Accuracy: 29.56%\n","| Global Round : 16 |\tLoss avg: 1.951459 \n","| Client : 40 | Average Loss: 1.9515 \n","| Global Round : 16 | Local Epoch : 1 | Loss: 1.938510 | Accuracy: 27.78%\n","| Global Round : 16 |\tLoss avg: 1.938510 \n","| Client : 47 | Average Loss: 1.9385 \n","| Global Round : 16 | Local Epoch : 1 | Loss: 1.925159 | Accuracy: 28.67%\n","| Global Round : 16 |\tLoss avg: 1.925159 \n","| Client : 26 | Average Loss: 1.9252 \n","| Global Round : 16 | Local Epoch : 1 | Loss: 1.962951 | Accuracy: 27.56%\n","| Global Round : 16 |\tLoss avg: 1.962951 \n","| Client : 0 | Average Loss: 1.9630 \n","| Global Round : 16 | Local Epoch : 1 | Loss: 1.966655 | Accuracy: 26.00%\n","| Global Round : 16 |\tLoss avg: 1.966655 \n","| Client : 78 | Average Loss: 1.9667 \n","\n","Average training statistics (global epoch) : 16\n","|---- Trainig Loss : 2.078049891955323\n","|---- Training Accuracy: 36.58% \n","\n","16-th round\n","average train loss 0.234 | test loss 0.173 | test acc: 0.240\n","Epoch: 17 \n","\n","| Global Round : 17 | Local Epoch : 1 | Loss: 1.839910 | Accuracy: 32.22%\n","| Global Round : 17 |\tLoss avg: 1.839910 \n","| Client : 22 | Average Loss: 1.8399 \n","| Global Round : 17 | Local Epoch : 1 | Loss: 1.857772 | Accuracy: 29.78%\n","| Global Round : 17 |\tLoss avg: 1.857772 \n","| Client : 78 | Average Loss: 1.8578 \n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-b5428ba9dea1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midxs_users\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mlocal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLocalUpdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         w, loss = local_model.update_weights(model=copy.deepcopy(model), # pass the global model to the clients\n\u001b[0m\u001b[1;32m     16\u001b[0m                                              global_round=epoch)\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'| Client : {} | Average Loss: {:.4f} '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/FL2022/FedAVG/update.py\u001b[0m in \u001b[0;36mupdate_weights\u001b[0;34m(self, model, global_round)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0mlog_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/FL2022/FedAVG/modelRN50.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"wEABlJEzHps3"},"source":["#Storing the Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VEyGlnuNHpEy","executionInfo":{"status":"aborted","timestamp":1675870782302,"user_tz":-60,"elapsed":4,"user":{"displayName":"Alessandro","userId":"00700822641677625485"}}},"outputs":[],"source":["dict_ = {'train_acc' : train_accuracy, 'train_loss' : train_loss}\n","df = pd.DataFrame(dict_) \n","iid = ['iid' if args.iid else 'nonIID']\n","unb = ['unbalanced' if unbalanced and not args.iid else 'balanced' ]\n","bs = args.local_bs \n","filename = f\"fedAVG_{iid}_{unb}_{args.norm}{bs}_{args.epochs}_lr_{args.lr}_optimizer_{args.optimizer}\"\n","df = pd.DataFrame(dict_) \n","df.to_csv('/content/drive/MyDrive/FL2022/FedAVG/Results/'+filename+'.csv', encoding='utf-8')"]},{"cell_type":"markdown","metadata":{"id":"KMZgTc-EKEe-"},"source":["Showing the Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KboHhU1DHZnk","executionInfo":{"status":"aborted","timestamp":1675870782302,"user_tz":-60,"elapsed":4,"user":{"displayName":"Alessandro","userId":"00700822641677625485"}}},"outputs":[],"source":["print(f' \\n Results after {args.epochs} global rounds of training:')\n","print(\"|---- Avg Train Accuracy: {:.2f}%\".format(100*train_accuracy[-1]))\n"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"69935a36e45e41738f057902a303ba96":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a874d9c8045244bcb0fb4c41facb105e","IPY_MODEL_4550731bfd294f33be2ea4b14f4a03a1","IPY_MODEL_c7abc91bf8f44bb4b7b05bcc1806aff6"],"layout":"IPY_MODEL_5092fda393a74d0b906117ac12d11f8f"}},"a874d9c8045244bcb0fb4c41facb105e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_26b2b519bbb7483cba08c35ab05fcd0a","placeholder":"","style":"IPY_MODEL_5b63a9fee58c43b88a5ae6afd7dedd87","value":"100%"}},"4550731bfd294f33be2ea4b14f4a03a1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_942a1558abce4d7190c0df65b1cbf508","max":170498071,"min":0,"orientation":"horizontal","style":"IPY_MODEL_71b8d149b1bc4caf8e687e3607e70678","value":170498071}},"c7abc91bf8f44bb4b7b05bcc1806aff6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ae0f63a6d594aaeab195360d7b193be","placeholder":"","style":"IPY_MODEL_c59d153341c2437cbc451b2fc34aa37d","value":" 170498071/170498071 [00:01&lt;00:00, 109653071.32it/s]"}},"5092fda393a74d0b906117ac12d11f8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26b2b519bbb7483cba08c35ab05fcd0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b63a9fee58c43b88a5ae6afd7dedd87":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"942a1558abce4d7190c0df65b1cbf508":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71b8d149b1bc4caf8e687e3607e70678":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8ae0f63a6d594aaeab195360d7b193be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c59d153341c2437cbc451b2fc34aa37d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}